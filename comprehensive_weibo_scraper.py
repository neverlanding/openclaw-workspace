#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®åšçƒ­æœç»¼åˆçˆ¬è™«è„šæœ¬
ç»“åˆå¤šç§æ–¹æ³•è·å–å¾®åšçƒ­æœæ•°æ®
"""

import urllib.request
import urllib.parse
import json
import re
import time
from datetime import datetime
import subprocess
import sys


class ComprehensiveWeiboScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'https://s.weibo.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'X-Requested-With': 'XMLHttpRequest',
        }

    def http_request(self, url):
        """
        å‘é€HTTPè¯·æ±‚ï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œç¼–ç å¤„ç†
        """
        req = urllib.request.Request(url, headers=self.headers)
        for attempt in range(3):  # å°è¯•3æ¬¡
            try:
                response = urllib.request.urlopen(req, timeout=15)
                content = response.read()
                
                # å°è¯•å¤šç§ç¼–ç æ–¹å¼
                for encoding in ['utf-8', 'gbk', 'gb2312', 'latin-1']:
                    try:
                        return content.decode(encoding)
                    except UnicodeDecodeError:
                        continue
                        
                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯å¿½ç•¥
                return content.decode('utf-8', errors='ignore')
                
            except Exception as e:
                print(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/3): {str(e)}")
                if attempt < 2:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                else:
                    return None

    def method1_api_request(self):
        """
        æ–¹æ³•1: ä½¿ç”¨å¾®åšAPIç«¯ç‚¹
        """
        print("å°è¯•æ–¹æ³•1: ä½¿ç”¨å¾®åšAPI...")
        
        urls = [
            "https://m.weibo.cn/api/container/getIndex?containerid=106003%2Btype%3D25%26t%3D3%26disable_hot%3D1%26filter_type%3Drealtimehot",
            "https://m.weibo.cn/api/container/getIndex?containerid=106003type=25&filter_type=realtimehot&ignore_gazette=1&extparam=filter_type%3Drealtimehot%26mi_cid%3D100103%26pos%3D0_0%26c_type%3D30%26display_time%3D1616046282%26from%3D1110006030%26static_page%3Dhttps%253A%252F%252Fpay.sc.weibo.com%252Faj%252Fpay%252Fpindex%252Fcharge%252Fextend%252Findex.php%253Fproduct_id%253D10000033%2526parent%253D10000001%2526skin%253D10000002%2526product_name%253D%2525E9%2525B9%252585%2525E9%2525B8%2525A3%2525E6%25258E%252592%2525E8%2525A1%25258C%2525E6%2525A6%25259C%2526product_desc%253D%2525E9%2525B9%252585%2525E9%2525B8%2525A3%2525E6%25258E%252592%2525E8%2525A1%25258C%2525E6%2525A6%25259C%2526product_amount%253D0%2526order_id%253D",
        ]
        
        for url in urls:
            response_text = self.http_request(url)
            if response_text:
                try:
                    data = json.loads(response_text)
                    if data.get('ok') == 1:
                        cards = data['data'].get('cards', [])
                        
                        hot_searches = []
                        for card in cards:
                            if card.get('card_type') == 'feed':
                                for item in card.get('card_group', []):
                                    hot_search_item = {}
                                    
                                    # æå–æ ‡é¢˜
                                    title = item.get('raw_title', '')
                                    if title:  # åªæ·»åŠ æœ‰æ ‡é¢˜çš„é¡¹ç›®
                                        hot_search_item['title'] = title
                                        
                                        # æå–æ’å
                                        rank = item.get('rank', len(hot_searches) + 1)
                                        hot_search_item['rank'] = rank
                                        
                                        # æå–é“¾æ¥
                                        scheme = item.get('scheme', '')
                                        hot_search_item['link'] = scheme
                                        
                                        # æå–æè¿°ä¿¡æ¯
                                        desc = item.get('desc', '')
                                        hot_search_item['desc'] = desc
                                        
                                        hot_searches.append(hot_search_item)
                        
                        if hot_searches:
                            print(f"æ–¹æ³•1æˆåŠŸï¼Œè·å–åˆ° {len(hot_searches)} æ¡æ•°æ®")
                            return hot_searches
                            
                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    print(f"è§£æAPIå“åº”æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        print("æ–¹æ³•1å¤±è´¥")
        return None

    def method2_web_scraping(self):
        """
        æ–¹æ³•2: ç›´æ¥ç½‘é¡µæŠ“å–
        """
        print("å°è¯•æ–¹æ³•2: ç›´æ¥ç½‘é¡µæŠ“å–...")
        
        url = "https://s.weibo.com/top/summary"
        response_text = self.http_request(url)
        
        if not response_text:
            print("æ–¹æ³•2å¤±è´¥ï¼šæ— æ³•è·å–ç½‘é¡µå†…å®¹")
            return None
        
        try:
            # å°è¯•å¤šç§æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…çƒ­æœæ•°æ®
            # æ–¹å¼1: å°è¯•åŒ¹é…JSONæ•°æ®å—
            script_pattern = r'<script[^>]*>.*?window\.pageConfig\s*=\s*(.*?)\s*</script>'
            json_match = re.search(script_pattern, response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1).strip().rstrip(';')
                # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON
                if not json_str.startswith('{') and not json_str.startswith('['):
                    # æŸ¥æ‰¾çœŸæ­£çš„JSONå¼€å§‹ä½ç½®
                    start_pos = json_str.find('{')
                    if start_pos == -1:
                        start_pos = json_str.find('[')
                    if start_pos != -1:
                        json_str = json_str[start_pos:]
                
                try:
                    data = json.loads(json_str)
                    print("æ–¹æ³•2æˆåŠŸï¼Œä»é¡µé¢æ‰¾åˆ°äº†JSONæ•°æ®")
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„è¿›è¡Œè§£æ
                    return self._parse_json_data(data)
                except:
                    pass
            
            # æ–¹å¼2: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–é“¾æ¥å’Œæ–‡æœ¬
            # åŒ¹é…çƒ­æœé¡¹çš„æ¨¡å¼
            patterns = [
                r'<a[^>]*href="([^"]*)"[^>]*title="([^"]*)"[^>]*>',
                r'<a[^>]*title="([^"]*)"[^>]*href="([^"]*)"[^>]*>',
                r'<td class="td-02">[^<]*<a[^>]+>([^<]+)</a>',
                r'data-v-[a-z0-9]+="[^"]*">([^<]*)</span>',  # Vue.jsåº”ç”¨å¯èƒ½ä½¿ç”¨çš„æ¨¡å¼
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, response_text)
                if matches:
                    hot_searches = []
                    for i, match in enumerate(matches[:20], 1):
                        if isinstance(match, tuple):
                            if len(match) >= 2:
                                link, title = match[0], match[1]
                            else:
                                title = match[0]
                                link = ""
                        else:
                            title = match
                            link = ""
                        
                        if title.strip():  # ç¡®ä¿æ ‡é¢˜ä¸ä¸ºç©º
                            hot_searches.append({
                                'rank': i,
                                'title': title.strip(),
                                'link': link if link.startswith('http') else f"https://s.weibo.com{link}"
                            })
                    
                    if hot_searches:
                        print(f"æ–¹æ³•2æˆåŠŸï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼è·å–åˆ° {len(hot_searches)} æ¡æ•°æ®")
                        return hot_searches
            
            print("æ–¹æ³•2å¤±è´¥ï¼šæ— æ³•ä»ç½‘é¡µæå–æœ‰æ•ˆæ•°æ®")
            return None
            
        except Exception as e:
            print(f"æ–¹æ³•2å¤„ç†ç½‘é¡µæ—¶å‡ºé”™: {str(e)}")
            return None

    def _parse_json_data(self, data):
        """
        è§£æä»é¡µé¢è·å–çš„JSONæ•°æ®
        """
        # æ ¹æ®å¯èƒ½çš„æ•°æ®ç»“æ„è¿›è¡Œè§£æ
        hot_searches = []
        
        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«çƒ­æœæ•°æ®çš„å­—æ®µ
        if isinstance(data, dict):
            # æœç´¢å¸¸è§çš„é”®å
            keys_to_try = ['data', 'result', 'list', 'items', 'hot_list']
            for key in keys_to_try:
                if key in data:
                    result = self._parse_json_data(data[key])
                    if result:
                        return result
        
        # å¦‚æœæ˜¯æ•°ç»„ï¼Œç›´æ¥è§£ææ¯ä¸ªå…ƒç´ 
        elif isinstance(data, list):
            for i, item in enumerate(data[:20], 1):
                if isinstance(item, dict):
                    title = item.get('title') or item.get('name') or item.get('word') or item.get('keyword')
                    if title:
                        hot_searches.append({
                            'rank': i,
                            'title': title,
                            'link': item.get('link', ''),
                            'desc': item.get('desc', '')
                        })
        
        return hot_searches if hot_searches else None

    def method3_alternative_source(self):
        """
        æ–¹æ³•3: ä½¿ç”¨æ›¿ä»£æ•°æ®æº
        """
        print("å°è¯•æ–¹æ³•3: ä½¿ç”¨æ›¿ä»£æ•°æ®æº...")
        
        # å°è¯•ä¸€äº›å…¬å¼€çš„å¾®åšçƒ­æœAPIï¼ˆå¦‚æœæœ‰ï¼‰
        # æ³¨æ„ï¼šè¿™äº›é€šå¸¸æ˜¯ç¬¬ä¸‰æ–¹æœåŠ¡ï¼Œç¨³å®šæ€§å’Œå‡†ç¡®æ€§æ— æ³•ä¿è¯
        alt_sources = [
            # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸€äº›å…¬å¼€çš„APIç«¯ç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        ]
        
        for source in alt_sources:
            response_text = self.http_request(source)
            if response_text:
                try:
                    data = json.loads(response_text)
                    # è§£ææ•°æ®...
                    print("æ–¹æ³•3æˆåŠŸ")
                    return self._parse_json_data(data)
                except:
                    continue
        
        print("æ–¹æ³•3å¤±è´¥")
        return None

    def format_report(self, hot_searches):
        """
        æ ¼å¼åŒ–æŠ¥å‘Š
        """
        if not hot_searches:
            return "æœªèƒ½è·å–åˆ°å¾®åšçƒ­æœæ•°æ®"
        
        report = []
        report.append("=" * 60)
        report.append("å¾®åšå®æ—¶çƒ­æœæ¦œ")
        report.append(f"æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 60)
        
        for item in hot_searches[:20]:  # åªæ˜¾ç¤ºå‰20æ¡
            rank = item.get('rank', '')
            title = item.get('title', 'N/A')
            link = item.get('link', '')
            desc = item.get('desc', '')
            
            # æ·»åŠ æ’åæ ·å¼
            if rank == 1:
                rank_str = f"ğŸ† {rank:2d}"
            elif rank == 2:
                rank_str = f"ğŸ¥ˆ {rank:2d}"
            elif rank == 3:
                rank_str = f"ğŸ¥‰ {rank:2d}"
            else:
                rank_str = f"  {rank:2d}"
                
            report.append(f"{rank_str}. {title}")
            if desc:
                report.append(f"     {desc}")
            if link:
                report.append(f"     é“¾æ¥: {link}")
            report.append("")
        
        report.append("=" * 60)
        report.append(f"å…±è·å– {len(hot_searches)} æ¡çƒ­æœä¿¡æ¯")
        report.append("=" * 60)
        
        return "\n".join(report)

    def run(self):
        """
        è¿è¡Œçˆ¬è™«ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒæ–¹æ³•
        """
        print("å¼€å§‹è·å–å¾®åšçƒ­æœæ•°æ®...")
        print("æ­£åœ¨å°è¯•å¤šç§æ–¹æ³•ä»¥ç»•è¿‡è®¿é—®é™åˆ¶...")
        
        methods = [
            self.method1_api_request,
            self.method2_web_scraping,
            self.method3_alternative_source
        ]
        
        for method in methods:
            result = method()
            if result:
                report = self.format_report(result)
                print(report)
                
                # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"comprehensive_weibo_hot_search_{timestamp}.txt"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(report)
                print(f"\næ•°æ®å·²ä¿å­˜åˆ°: {filename}")
                
                return result
        
        print("æ‰€æœ‰æ–¹æ³•éƒ½æœªèƒ½æˆåŠŸè·å–æ•°æ®")
        print("å¯èƒ½çš„åŸå› :")
        print("- å¾®åšæ›´æ”¹äº†APIæ¥å£æˆ–é¡µé¢ç»“æ„")
        print("- å½“å‰IPè¢«é™åˆ¶è®¿é—®")
        print("- ç½‘ç»œè¿æ¥é—®é¢˜")
        print("- éœ€è¦æ›´å¤æ‚çš„ååçˆ¬è™«æªæ–½ï¼ˆå¦‚ä»£ç†ã€æµè§ˆå™¨è‡ªåŠ¨åŒ–ç­‰ï¼‰")
        
        return None


def main():
    scraper = ComprehensiveWeiboScraper()
    result = scraper.run()


if __name__ == "__main__":
    main()